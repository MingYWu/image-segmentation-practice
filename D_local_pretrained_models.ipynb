{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄像头预测-OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../seg-2/mmsegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import mmcv\n",
    "from mmseg.apis import init_model, inference_model\n",
    "\n",
    "from mmseg.datasets.ade import ADE20KDataset\n",
    "from mmseg.datasets.cityscapes import CityscapesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型设置选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(dataset, model):\n",
    "    if dataset == 'cityscapes':\n",
    "        if model == 'UNet':\n",
    "            # Unet\n",
    "            config_file = 'configs/unet/unet-s5-d16_fcn_4xb4-160k_cityscapes-512x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/unet/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes_20211210_145204-6860854e.pth'\n",
    "        elif model == 'DeepLabV3+':\n",
    "            # DeepLabV3+, R-50-D8\t512x1024\n",
    "            config_file = 'configs/deeplabv3plus/deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/deeplabv3plus/deeplabv3plus_r50-d8_512x1024_80k_cityscapes/deeplabv3plus_r50-d8_512x1024_80k_cityscapes_20200606_114049-f9fb496d.pth'\n",
    "        elif model == 'FastSCNN':\n",
    "            # FastSCNN\n",
    "            config_file = 'configs/fastscnn/fast_scnn_8xb4-160k_cityscapes-512x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/fast_scnn/fast_scnn_lr0.12_8x4_160k_cityscapes/fast_scnn_lr0.12_8x4_160k_cityscapes_20210630_164853-0cec9937.pth'\n",
    "        elif model == 'SegFormer':\n",
    "            # SegFormer, MIT-B5\t1024x1024\t\n",
    "            config_file = 'configs/segformer/segformer_mit-b5_8xb1-160k_cityscapes-1024x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n",
    "        elif model == 'Mask2Former':\n",
    "            # Mask2Former, Swin-B (in22k)\t512x1024\t\n",
    "            config_file = 'configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221203_045030-9a86a225.pth'\n",
    "    elif dataset == 'ade20k':\n",
    "        if model == 'DeepLabV3+':\n",
    "            config_file = 'configs/deeplabv3plus/deeplabv3plus_r50-d8_4xb4-80k_ade20k-512x512.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/deeplabv3plus/deeplabv3plus_r50-d8_512x512_80k_ade20k/deeplabv3plus_r50-d8_512x512_80k_ade20k_20200614_185028-bf1400d8.pth'\n",
    "        elif model == 'pspnet':\n",
    "            config_file ='configs/pspnet/pspnet_r50-d8_4xb4-80k_ade20k-512x512.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x512_160k_ade20k/pspnet_r50-d8_512x512_160k_ade20k_20200615_184358-1890b0bd.pth'\n",
    "        elif model == 'SegFormer':\n",
    "            config_file = 'configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-512x512.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'\n",
    "        elif model == 'MaskFormer':\n",
    "            config_file = 'configs/maskformer/maskformer_swin-s_upernet_8xb2-160k_ade20k-512x512.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/maskformer/maskformer_swin-s_upernet_8xb2-160k_ade20k-512x512/maskformer_swin-s_upernet_8xb2-160k_ade20k-512x512_20221115_114710-723512c7.pth'\n",
    "        elif model == 'Mask2Former':\n",
    "            config_file = 'configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640_20221203_235230-7ec0f569.pth'\n",
    "        \n",
    "    return config_file, checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_palette(dataset):\n",
    "    if dataset == 'cityscapes':\n",
    "        METAINFO = CityscapesDataset.METAINFO\n",
    "        palette = [[class_name, color] for class_name, color in zip(METAINFO['classes'], METAINFO['palette'])]\n",
    "    elif dataset == 'ade20k':\n",
    "        METAINFO = ADE20KDataset.METAINFO\n",
    "        palette = [[class_name, color] for class_name, color in zip(METAINFO['classes'], METAINFO['palette'])]\n",
    "    elif dataset == 'watermelon':\n",
    "        palette = [\n",
    "            ['background', [127,127,127]],\n",
    "            ['red', [0,0,200]],\n",
    "            ['green', [0,200,0]],\n",
    "            ['white', [144,238,144]],\n",
    "            ['seed-black', [30,30,30]],\n",
    "            ['seed-white', [8,189,251]]]\n",
    "\n",
    "    palette_dict = {}\n",
    "    for idx, each in enumerate(palette):\n",
    "        palette_dict[idx] = each[1]\n",
    "\n",
    "    return palette_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 调用摄像头，处理帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_frame(img_bgr, model, palette_dict):\n",
    "\n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 语义分割预测\n",
    "    result = inference_model(model, img_bgr)\n",
    "    pred_mask = result.pred_sem_seg.data[0].cpu().numpy()\n",
    "\n",
    "    # 将预测的整数ID，映射为对应类别的颜色\n",
    "    pred_mask_bgr = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3))\n",
    "    for idx in palette_dict.keys():\n",
    "        pred_mask_bgr[np.where(pred_mask==idx)] = palette_dict[idx]\n",
    "    pred_mask_bgr = pred_mask_bgr.astype('uint8')\n",
    "\n",
    "    # 透明度，越大越接近原图\n",
    "    opacity = 0.4\n",
    "\n",
    "    # 将语义分割预测图和原图叠加显示\n",
    "    pred_viz = cv2.addWeighted(img_bgr, opacity, pred_mask_bgr, 1-opacity, 0)\n",
    "\n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)\n",
    "\n",
    "    # 在画面上写字：图片，字符串，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "    scaler = 1 # 文字大小\n",
    "    FPS_string = 'FPS {:.2f}'.format(FPS) # 写在画面上的字符串\n",
    "    img_bgr = cv2.putText(pred_viz, FPS_string, (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "    return img_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型设置，抓拍一张，分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def capture_and_process_image(dataset, model_name, output_width, output_height):\n",
    "    # device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    device = 'cpu'\n",
    "\n",
    "    # 模型设置\n",
    "    config_file, checkpoint_file = config(dataset, model_name)\n",
    "    model = init_model(config_file, checkpoint_file, device=device)\n",
    "\n",
    "    # 分割图像不同类别的配色设置\n",
    "    palette_dict = config_palette(dataset)\n",
    "\n",
    "    # 获取摄像头，0为电脑默认摄像头，1为外接摄像头\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # 等一秒，拍照\n",
    "    time.sleep(1)\n",
    "    # 从摄像头捕获一帧画面\n",
    "    success, frame = cap.read()\n",
    "    cap.release() # 关闭摄像头\n",
    "    cv2.destroyAllWindows() # 关闭图像窗口\n",
    "\n",
    "    # 确保宽度和高度都是16的倍数\n",
    "    output_width = (output_width // 16) * 16\n",
    "    output_height = (output_height // 16) * 16\n",
    "\n",
    "    # 调整图像大小，使其满足模型的要求\n",
    "    frame = cv2.resize(frame, (output_width, output_height))\n",
    "\n",
    "    # 显示抓拍结果\n",
    "    plt.figure(figsize=(output_width/80, output_height/80))  # 调整输出图像大小\n",
    "    plt.imshow(frame[:,:,::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    # 处理并显示分割结果\n",
    "    frame = process_frame(frame, model, palette_dict)\n",
    "    plt.figure(figsize=(output_width/80, output_height/80))  # 调整输出图像大小\n",
    "    plt.imshow(frame[:,:,::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cityscapes'\n",
    "model_name = 'FastSCNN'\n",
    "capture_and_process_image(dataset, model_name, output_width=512, output_height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cityscapes'\n",
    "model_name = 'UNet'\n",
    "capture_and_process_image(dataset, model_name, output_width=512, output_height=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用摄像头逐帧实时处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RealtimeDetect(dataset, model_name):\n",
    "    device = 'cpu'\n",
    "\n",
    "    # 模型设置\n",
    "    config_file, checkpoint_file = config(dataset, model_name)\n",
    "    model = init_model(config_file, checkpoint_file, device=device)\n",
    "    \n",
    "    # 分割图像不同类别的配色设置\n",
    "    palette_dict = config_palette(dataset)\n",
    "    \n",
    "    # 获取摄像头，传入0表示获取系统默认摄像头\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    # 打开cap\n",
    "    cap.open(0)\n",
    "\n",
    "    # 无限循环，直到break被触发\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        # 获取画面\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if not success: # 如果获取画面不成功，则退出\n",
    "            print('获取画面不成功，退出')\n",
    "            break\n",
    "        \n",
    "        ## 逐帧处理\n",
    "        frame = process_frame(frame, model, palette_dict)\n",
    "        \n",
    "        # 展示处理后的三通道图像\n",
    "        cv2.imshow('my_window',frame)\n",
    "        \n",
    "        key_pressed = cv2.waitKey(60) # 每隔多少毫秒毫秒，获取键盘哪个键被按下\n",
    "\n",
    "        if key_pressed in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "            break\n",
    "        \n",
    "    # 关闭摄像头\n",
    "    cap.release()\n",
    "\n",
    "    # 关闭图像窗口\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cityscapes'\n",
    "model_name = 'FastSCNN'\n",
    "RealtimeDetect(dataset, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ade20k'\n",
    "model_name = 'deeplabv3+'\n",
    "RealtimeDetect(dataset, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
