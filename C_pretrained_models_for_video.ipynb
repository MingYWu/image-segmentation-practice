{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Segmentation Model predict Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不删除逐帧的预测\n",
    "# !python3 C_pretrained_models_for_video.py --temp_dir_delete False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "1. 本项目输出的文件在根目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-17 22:46:18,701] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmy/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import mmengine\n",
    "from mmseg.apis import init_model, inference_model\n",
    "from mmseg.utils import register_all_modules\n",
    "register_all_modules()\n",
    "\n",
    "from mmseg.datasets import CityscapesDataset\n",
    "\n",
    "# os.chdir('mmsegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_frame(model, img, palette, opacity=0.2):\n",
    "    \n",
    "    result = inference_model(model, img)\n",
    "    \n",
    "    # 将分割图按调色板染色\n",
    "    seg_map = np.array(result.pred_sem_seg.data[0].detach().cpu().numpy()).astype('uint8')\n",
    "    seg_img = Image.fromarray(seg_map).convert('P')\n",
    "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "    \n",
    "    show_img = (np.array(seg_img.convert('RGB')))*(1-opacity) + img*opacity\n",
    "    \n",
    "    return show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, dataset, input_video):\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    if dataset == 'cityscapes':\n",
    "        from mmseg.datasets import cityscapes\n",
    "        classes = cityscapes.CityscapesDataset.METAINFO['classes']\n",
    "        palette = cityscapes.CityscapesDataset.METAINFO['palette']\n",
    "        \n",
    "        if model == 'segformer':\n",
    "            # 模型 config 配置文件\n",
    "            config_file = './mmsegmentation/configs/segformer/segformer_mit-b5_8xb1-160k_cityscapes-1024x1024.py'\n",
    "            # 模型 checkpoint 权重文件\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n",
    "        elif model == 'mask2former':\n",
    "            config_file = './mmsegmentation/configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221203_045030-9a86a225.pth'\n",
    "    \n",
    "    elif dataset == 'ADE20K':\n",
    "        from mmseg.datasets import ade\n",
    "        classes = ade.ADE20KDataset.METAINFO['classes']\n",
    "        palette = ade.ADE20KDataset.METAINFO['palette']\n",
    "        \n",
    "        if model == 'mask2former':\n",
    "            config_file = './mmsegmentation/configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640.py'\n",
    "            checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640_20221203_235230-7ec0f569.pth'\n",
    "    \n",
    "    model = init_model(config_file, checkpoint_file, device=device)\n",
    "    \n",
    "    temp_out_dir = time.strftime('%Y%m%d%H%M%S')\n",
    "    os.mkdir(temp_out_dir)\n",
    "    print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))\n",
    "    \n",
    "    # 读入待预测视频\n",
    "    imgs = mmcv.VideoReader(input_video)\n",
    "\n",
    "    prog_bar = mmengine.ProgressBar(len(imgs))\n",
    "\n",
    "    # 对视频逐帧处理\n",
    "    for frame_id, img in enumerate(imgs):\n",
    "        \n",
    "        ## 处理单帧画面\n",
    "        show_img = predict_single_frame(model, img, palette, opacity=0.15)\n",
    "        # 保存语义分割预测结果图像至临时文件夹\n",
    "        temp_path = f'{temp_out_dir}/{frame_id:06d}.jpg' \n",
    "        cv2.imwrite(temp_path, show_img)\n",
    "\n",
    "        prog_bar.update() # 更新进度条\n",
    "\n",
    "    # 把每一帧串成视频文件\n",
    "    mmcv.frames2video(temp_out_dir, './outputs/'+f'out_{model}_{dataset}'+'.mp4', fps=imgs.fps, fourcc='mp4v')\n",
    "\n",
    "    shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹\n",
    "    print('删除临时文件夹', temp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmy/anaconda3/lib/python3.9/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/wmy/anaconda3/lib/python3.9/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth\n",
      "创建临时文件夹 20230917224622 用于存放每帧预测结果\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 168/168, 68.4 task/s, elapsed: 2s, ETA:     0s[                                                  ] 0/168, elapsed: 0s, ETA:\n",
      "删除临时文件夹 20230917224622\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cityscapes'\n",
    "model = 'segformer'\n",
    "\n",
    "if dataset == 'cityscapes':\n",
    "    # input_video = 'data/traffic.mp4'\n",
    "    # input_video = 'data/street_20220330_174028.mp4'\n",
    "    input_video = 'data/street_5s.mp4'  # mydata-street\n",
    "elif dataset == 'ADE20K':\n",
    "    # input_video = 'data/Library_8s.mp4'\n",
    "    input_video = 'data/Library_5s.mp4'\n",
    "    \n",
    "main(model=model, dataset=dataset, input_video=input_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
